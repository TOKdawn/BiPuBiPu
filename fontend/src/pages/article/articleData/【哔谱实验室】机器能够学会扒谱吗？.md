能，但还不够好。

目前乐谱识别领域的方法主要分为两类：

（1）two stage的乐谱识别算法：音乐>主旋律>乐谱

（2）one stage的乐谱识别算法：音乐>乐谱

##  MIR与旋律提取

音乐是一种历史悠久的艺术形式，它包括多个形式要素（即表现手段），如旋律、节奏、和声、音色、力度、速度、调式、曲式等。其中最基本的要素是旋律和节奏。旋律与人类听觉感知相关，但是在音乐学研究中并没有清晰的定义。

近二十年来，音频信息处理技术的发展和互联网的兴起，使得音乐形式逐渐从传统的磁带、黑胶唱片过渡到数字音乐。

![拥有midi接口的电子设备](http://upload-images.jianshu.io/upload_images/2141706-f31680ce9d156f6b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们每个人可能都会在自己的电脑或者移动设备中存储上百首歌曲，而云端的音乐服务提供商经常需要存储几百万甚至上千万的歌曲。如此海量的音乐再也无法依靠人工进行管理，需要i新的方法对其进行描述、分类、搜索、交互。

![image](http://upload-images.jianshu.io/upload_images/2141706-0b9e9baa253d31ca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

因此，基于内容的音乐信息检索（Music Information Retrieval, MIR）成为了热门研究领域，并在最近二十年得到了迅速发展。

在MIR领域，通常认为旋律属于混合音频信号中的单个声源，这个声源一般是人声或其中最主要的乐器。从信号处理的角度出发，音乐可以被分为单音音乐（monophonic music）和多音音乐（polyphonic music）两种。前者指在任意时刻只有一个音符同时发声；后者指在同一时刻有两个以上的音符同时发声，音符可以来自不同的乐器（例如歌声、吉他或贝斯），或同时演奏多个音符的单个乐器（例如钢琴）。旋律提取处理的对象是多音音乐信号，自动估计对应于旋律单音音符序列的主音高（predominant pitch）或主基频（predominant fundamental frequency，f0）。

> 注：这里的音高是一个感知概念，而主基频是一个物理量，在音乐计算文献中经常被等价使用。

![从音频信号中提取旋律音高序列](http://upload-images.jianshu.io/upload_images/2141706-c6d86c1fd8ec1f38.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240) 

近几年，用计算机进行旋律提取（或主基频估计）已经成为数字音乐计算领域的一个重要研究课题。虽然人（dalao）可以从混合音乐信号中轻松地辨别旋律，甚至乐感良好并接受专业训练的人可以将旋律识别为乐谱（如JE吧dalao），但是由机器来执行这个任务却是复杂且具有极大挑战的。

##  旋律提取的难点

（1）一个多音音乐信号由录音中的所有乐器产生的声音波形叠加组成，很多时候这些乐器同时演奏。把来自不同声源、按照和声结构高度耦合叠加在一起的频谱分开到对应各个音符是极其困难的，而后期混响、回声等处理会进一步增加声源的重叠，模糊音乐信号的起止时间（note onset/offset），使频谱分离更加困难。

（2）即使已经得到音符的基频序列，还需要判断哪些音高属于旋律，哪些属于伴奏，当旋律为歌声但是存在背景和声时，检测更加困难（Adobe公司开发的去除人声算法已经被集成到Audition中，但由于商业保密无法得知技术细节）。

##  旋律提取的研究现状

旋律提取与单音音高估计和多音音高估计不同。 其与单音音高估计的区别在于旋律提取处理的是多音音乐信号；与多音音高估计的区别在于旋律提取只识别旋律的音高，同时与其他声源的音高进行区分。

（1） 基于音高显著度（pitch salience）的旋律提取方法

![基于音高显著度的旋律提取方法的一般步骤](http://upload-images.jianshu.io/upload_images/2141706-406e1b2fdab023db.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

（2） 基于声源分离的旋律提取方法

（3） 基于数据驱动的旋律提取方法

（4） 基于多个单音音高估计器的旋律提取方法

##  八度错误（octave errors）

检测到的旋律音高f0候选值有时是真实f0的整数倍或分数倍，算法经常会选择位于输出旋律正确音高上下一个八度的f0。

##  旋律提取的应用

除了乐谱识别（music transcription），旋律提取技术还有许多直接和间接的应用。

直接应用：音准分析（intonation analysis）、旋律主题和模式分析（melodic motif and pattern analysis）、电声作曲（electroacoustic composition）、鬼畜分析（kichiku analysis）

间接应用：哼唱检索（query by humming）、翻唱检索（cover song identification）、流派分类（genre classification）、歌声消除（vocal cut）、伴奏自动生成、歌唱家识别、音乐借用（music borrowing）

> 注：在音乐借用中，借用和被借用歌曲之间共享一个持续时间较短的相似旋律片段。通常，音乐界认为适当的借用在艺术创作中是允许的，但是超过8小节就涉嫌抄袭侵权行为。

##  听歌识曲的原理

通过窗口扫描（把音乐分割成一小段一小段的），然后提取这一段的声学特征，例如梅尔频率倒谱系数(Mel-FrequencyCepstralCoefficients，MFCCs)，就得到一个特征向量。对数据库的歌和用户录音的歌做同样的操作得到特征向量，然后两两之间计算相似度（两个向量的距离可以用余弦公式算夹角大小或者两点间距离公式来算）。

![听歌识曲流程图](http://upload-images.jianshu.io/upload_images/2141706-a5e9b1996af8cc80.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


## 

乐谱识别与CNN

当我们听到CNN（卷积神经网络），不是特朗普说Fake News那个CNN。通常会想到计算机视觉。图像分类的重大突破，以及当下大多数计算机视觉系统的核心，都要归功于CNN，从自动驾驶汽车到目标检测不外如是。

![Mask R-CNN 在COCO数据集上的目标检测&amp;分割结果](http://upload-images.jianshu.io/upload_images/2141706-f175f9f0ca3abd09.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



那么音乐又是怎么和图像扯上关系的呢？这一切都要从下面这个人说起。

![骚年，想学傅里叶变换吗？](http://upload-images.jianshu.io/upload_images/2141706-05da7b3246cc691d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


我们可以将音乐信号分割成时间帧，然后将时域信号变换到频域来进行分析。常用的时频变换包括短时傅里叶变换（STFT）、多分辨率变换（multiratefilterbank）、常数Q变换（constant-Q transform）以及多分辨率傅里叶变换（multi-resolution FFT, MRFFT）。

与STFT相比，常数Q变换等时频变换避免了时频分辨率均匀的缺点，更接近与人耳听觉系统，在低频有更高的频率分辨率来分解相近的音符，在高频有更高的时间分辨率来跟踪快速变化的泛音。

![STFT，线性频率尺度](http://upload-images.jianshu.io/upload_images/2141706-33d61ace00d660c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



![相同的音频，常数Q变换](http://upload-images.jianshu.io/upload_images/2141706-25fb2ff03cc8a503.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

##  来自音乐的图像

在一个典型的CNN中，首先将图像读取为三维数组（宽，高和3个颜色通道），然后将这些数据通过几层卷积，最大池和某种非线性传递，如ReLU。 在最后一层，为每个图像类（花，猫等）输出一个分数，表示输入属于该分类的可能性。 反向传播用于从一组标记的训练数据计算损失函数迭代更新卷积参数。

那么，音乐中的乐谱检测与图像识别有哪些相似之处呢？ 我们可以利用上述时频变换创建称为频谱图的音频图像，它们显示频率随时间如何变化。 如果将立体声音频中的左右声道视为类似于照片中的颜色通道，则频谱图图像与您要输入到图像识别神经网络中的三维图像矩阵极其相似。

但在概念上，在频谱图图像中找到音符与找到照片中的物体有多类似？ 音乐比较简单，频谱图通常仅由两种基本形状组成：谐波（窄频带，跨越很短的频率范围和很长的时间范围），以及鼓或其他宽带特征（它跨越了很短的时间范围和很长的频率范围）。同时，还不需要担心或缩放不同距离的旋转。 而且，我们只关心一个对象类：音符。

![对音乐片段进行常数Q变换得到的频域图像](http://upload-images.jianshu.io/upload_images/2141706-c583decaa68e293e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

但是音符识别的几个方面比物理图像更具挑战性。 在某些基波频率（如B♭3（233 Hz））中的音符由该基频的倍数处的谐波组成，随着上升幅度逐渐减小。 因此，与大多数物体不同，音符不会局限于输入的单个区域。

![B♭ 谐波（对数频率标度）](http://upload-images.jianshu.io/upload_images/2141706-5ed6d13963c4aa41.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

与物理图像不同，来自不同音符的谐波可能会相互干扰。在照片中，一个物体可以被另一个物体部分隐藏，但前面的物体不会发生任何变形。 不过，音符却会变形。 附近的谐波会导致振幅“跳动”，您可以在上图中的第4次和第5次谐波中看到这种振幅。 音符识别算法需要以某种方式考虑音乐的这些方面。

钢琴键只有88个输出节点，而不是图像类。由于一次处理整个谱图图像是不可行的，我们需要首先检测可能的音符起始点，然后创建以这些时间为中心的频谱图的矩形切片。可以训练单独的神经网络来识别这些位置，也可以在平均幅度变化中寻找局部最大值。

![以音符开始时间为中心的频谱图的矩形切片](http://upload-images.jianshu.io/upload_images/2141706-4e0159f9a6c8cde0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

音符起始点检测提供了CNN评估的样本，这些以红色矩形为界的区域就是CNN的输入。

有人使用微软的ResNet（残差网络）和一个包含3000个MIDI文件的250万个训练样例的数据集，成功训练了一个模型。

![残差学习单元](http://upload-images.jianshu.io/upload_images/2141706-557f4878d42e10e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

通过TensorFlow在980 Ti GPU上训练了几天之后，该模型在测试集上的准确率达到了99.200％。（该分数是由将88个输出中的每一个计为0或1，并测量与真值相匹配的所有输出的占比。需要注意的是，由于每个训练示例的数据集平均有3个音符和85个非音符。按照这种算分方法即使从未检测到任何音符，使用此测量的准确率也为96.6％）

![Loss, note accuracy, and frame-level accuracy for training batches](http://upload-images.jianshu.io/upload_images/2141706-1951bec6f4dcdabc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

该作者以及将该模型打包成软件，能够用导入的声音文件生成五线谱。感兴趣的同学可以下载下来试试准不准。（有30天的免费试用期）

![由Secret Base.mp3 生成的五线谱](http://upload-images.jianshu.io/upload_images/2141706-72d6ae0e4cbdde52.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

该软件下载地址：https://www.lunaverus.com/download

（需翻墙，Windows、MAC、Linux都有）

百度网盘：https://pan.baidu.com/s/1ptjCU5Bdqlpo9YypnSy3ug 密码：ht4s

（只有Windows和Linux）

##  乐谱识别与NLP

循环神经网络（Recurrent Neural Network）是一种节点定向连接成环的人工神经网络。这种网络的内部状态可以展示动态时序行为。不同于前馈神经网络的是，RNN可以利用它内部的记忆来处理任意时序的输入序列，这让它可以更容易处理如不分段的手写识别、语音识别等。被广泛使用于自然语言处理（Natural Language Processing，NLP）研究方向。

还记得我们之前做的一个小实验吗？用RNN（循环神经网络）来训练我们目前曲库中的1000余首数字谱，看看能得到什么奇葩 - -！

zytx121/je​github.com

![RNN训练片段](http://upload-images.jianshu.io/upload_images/2141706-08835197febfd831.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们发现虽然有些数字谱看起来有点像那么一回事，但是缺少了最关键的节奏。要知道，就像小伙伴们所说，节奏可是音乐的灵魂啊！

网上也有不少利用RNN来训练歌词以及编曲的文章，大家感兴趣可以看看。这里给大家找了个将大量钢琴的MIDI文件喂给RNN从而生成的钢琴片段，让小伙伴们体验一下RNN的魔力！https://www.youtube.com/watch?v=UoLyeauBsNk（需翻墙）

##  站在统计学肩膀上的NLP

自然语言从它产生开始，逐渐演变成一种上下文相关的信息表达和传递方式，因此让计算机处理自然语言，一个基本的问题就是为自然语言这种上下文相关的特性建立数学模型。这个模型就是我们常说的统计语言模型，它是今天所有NLP的基础，并且广泛应用于机器翻译、语音识别、印刷体或手写体识别、拼音纠错、汉字输入和文献查询。一般使用的是二元模型(马尔可夫链)，假设任意一个词出现的概率之和他前面一个词有关。由于大部分条件概率是零，所以要使用古德—图灵估计公式对其进行平滑处理，即卡茨退避法。Google的罗塞塔翻译系统和语音搜索系统，使用的是四元模型，该模型存储于500台以上的Google服务器上。2005年，Google使用比其他研究机构多几千甚至上万倍的数据，训练出了一个六元模型，开发出了当时世界上最好的机器翻译系统。（大数据引发的量变到质变）

![NLP部分应用](http://upload-images.jianshu.io/upload_images/2141706-89c7d42244c04d1d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


因为哔谱哔谱已经搭建了一个开源曲谱库的关系，所以我们就想是不是能够以曲谱库为依托，建立一个统计音乐模型，用于自然音乐处理(Natural Music Processing)方面的研究 。下图是我们通过整理、类比得到的NMP可能具有的相关前景。

![NMP可能的应用](http://upload-images.jianshu.io/upload_images/2141706-d1c1a5d259f6ae90.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

我们认为，NMP的首要工作还是建立一个完善且庞大的曲谱库。这样才能为统计音乐模型的训练提供充足的训练样本，避免模型的过拟合。二元模型具体实现设想如下：可以先将音乐按照节拍分成N小节，然后以小节为单位训练二元模型。不同应用时，分节粒度可能不同。

##  数字谱还是midi？

数字谱简单的说就是没有节奏的简谱，但我更愿意把数字谱理解为纯音乐的歌词。我们用乐器按照一定的节奏将这些歌词演奏出来，即音乐。如果用NLP类比，那么midi文件其实就像是把说的一个人说的一句话（包括语调，语气等）完完整整的录下来。而数字谱则像是把这句话给写在纸上，丢失了一部分信息。

![乐谱识别是不是也能当成通信问题？](http://upload-images.jianshu.io/upload_images/2141706-29bb21a0cdcc7c3d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


正如普通人很大几率可以从一句写在纸上的话还原出当时那个人的语气和语调（一般语文老师都会教 = =），那么我们是不是也能教会计算机从数字谱还原出原曲的节奏，甚至创造出比原曲更加适合这个数字谱的节奏呢？

数字谱被广泛使用于口琴演奏中。由于没有节奏，相比于简谱和五线谱的其扒谱成本更低。正因为如此，其更容易产生大量的数据集，而海量数据也正是深度学习的关键所在。同时，统计音乐模型可能还能够帮助进一步提高旋律提取以及CNN乐谱识别的准确率。

* * *

或许有一天，我们能够听见计算机算出的世界上最美妙的旋律呢？

或许有一天，我们会重新思考音乐究竟是什么？

我相信，这一切随着机器学习的飞速发展都不再遥远。

参考文献：

*   李伟, 冯相宜, 吴益明,等. 流行音乐主旋律提取技术综述[J]. 计算机科学, 2017, 44(5):1-5\.

*   《人工智能基础（高中版）》

*   https://www.lunaverus.com/cnn

![image](http://upload-images.jianshu.io/upload_images/2141706-1fdef15552ab1f0d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
